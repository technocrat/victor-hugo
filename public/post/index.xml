<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Locus: Richard Careaga</title>
    <link>/post/</link>
    <description>Recent content in Posts on Locus: Richard Careaga</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 11 Oct 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Cognitive Bias and the Data Scientist</title>
      <link>/2018/10/11/cognitive-bias-and-the-data-scientist/</link>
      <pubDate>Thu, 11 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/10/11/cognitive-bias-and-the-data-scientist/</guid>
      <description>As data scientists, we are not immune from cognitive bias. We do a lot to minimize it, we may even try to quantify it. But it is a part of our protoplasm and, especially, the protoplasm of our untrained clients.
A good place to start is the Monty Hall Problem. The pre-historic Let’s Make a Deal game show on broadcast television featured a host, Monty Hall, and contestants who were offered the chance to win fabulous prizes if they picked the right curtain, 1, 2, or 3.</description>
    </item>
    
    <item>
      <title>Ordinary Least Squares Linear Regression Walkthrough for Beginners</title>
      <link>/2018/09/30/ordinary-least-squares-linear-regression-walkthrough-for-beginners/</link>
      <pubDate>Sun, 30 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/09/30/ordinary-least-squares-linear-regression-walkthrough-for-beginners/</guid>
      <description>Ordinary Least Squares Linear Regression Ordinary linear least squares regression is one of the first statistical methods that anyone learns who is trying to understand how two sets of numbers relate. It has an undeserved reputation of being able to foretell the future, but it is mathematically tractable, simple to apply, and often yields either directly usable results or signals the need for more sophisticated tools.
The idea is simple enough, find the line that passes through points in Cartesian (x,y 2-dimensional space) that minimizes the total distance (another over-simplification) between each point and the line.</description>
    </item>
    
    <item>
      <title>Deboning linear regression output in Excel</title>
      <link>/2018/09/18/deboning-linear-regression-in-excel/</link>
      <pubDate>Tue, 18 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/09/18/deboning-linear-regression-in-excel/</guid>
      <description>A while back (https://goo.gl/1W11Zu), I outlined interpretation of the output of a multiple linear regression of data on Seattle area housing prices (https://www.kaggle.com/harlfoxem/housesalesprediction?login=true), which provides a convenient way to illustrate the usual output of a multiple linear regression model output in R. This is a 21K dataset with 19 variables on housing characteristics and sales price. It’s a cruddy model, used solely to pick apart the different data presented. Today, it’s Excel’s turn.</description>
    </item>
    
    <item>
      <title>Cognitive styles of data science</title>
      <link>/2018/09/10/cognitive-styles-of-data-science/</link>
      <pubDate>Mon, 10 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/09/10/cognitive-styles-of-data-science/</guid>
      <description>Yihui Xie of RMarkdown fame has a long, thoughtful post (https://goo.gl/WjA7t8) on a debate for and against working in various types of interactive notebooks, such as Juypter for the Python platform, IDEs like RStudio in its so-called “notebook mode” and the old school heavy code commenting, among other approaches. Although that’s the primary subject, he weaves in some astute observations of the differences among “data scientists” based on whether their perspective grows from data origins or is aimed at ultimately producing software.</description>
    </item>
    
    <item>
      <title>WaPo has some effective visualizations</title>
      <link>/2018/09/09/wapo-has-some-effective-visualizations/</link>
      <pubDate>Sun, 09 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/09/09/wapo-has-some-effective-visualizations/</guid>
      <description>One of the annoyances of online newspapers such as the NYT and WaPo is that they recycle content, usually off-the-news-cycle. But this sometimes gets offset by finding something you missed the first time.
In a recent article on six common occcupations that have changed from above-average to below average pay, the 2018-09-04 article by Andrew Van Dam and Heather Long is illustrated by some effective techniques.
One technique is using the colors in the caption to serve as a legend to color coding in the graphic.</description>
    </item>
    
    <item>
      <title>Deboning simple linear regression output in TensorFlow</title>
      <link>/2018/09/04/deboning-simple-linear-regression-output-in-tensorflow/</link>
      <pubDate>Tue, 04 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/09/04/deboning-simple-linear-regression-output-in-tensorflow/</guid>
      <description>A simple linear regression example in TensorFlow(TM) is given at (https://www.tensorflow.org/tutorials/keras/basic_regression). By default, it produces none of the outputs of linear regression, other than MAE or MSE, on request through a print statement.
Testing set Mean Abs Error: $2788.86 Time spent searching the documentation turned up no references to “intercept”, “coefficient”, “F-statistic”, “t-value,” or “p-value.”
I am only beginning to dip my toes into TensorFlow(TM). I suspect that it exists not so much as a suite of modeling tools so much as a platform to express them in n-dimensional space very efficiently.</description>
    </item>
    
    <item>
      <title>Go Not Considered Harmful</title>
      <link>/2018/09/02/go-not-considered-harmful/</link>
      <pubDate>Sun, 02 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/09/02/go-not-considered-harmful/</guid>
      <description>I had my first exposure to programming in a FORTRAN class with real punchcards, back in the day, before I knew that GOTO was considered harmful. The exposure was brief and left me wondering whether Russian verbs of motion might not be easier to study, after all.
In the years to follow, I ran the occasional canned deck with my datacards through overnight batch queues, but did not return to anything that could be called programming until I acquired an HP-25 calculator with a macro language, followed shortly by an HP-97 with little magnetic strips on which to record them.</description>
    </item>
    
    <item>
      <title>The Unbearable Lightness of Coloring Maps</title>
      <link>/2018/08/31/the-unbearable-lightness-of-coloring-maps/</link>
      <pubDate>Fri, 31 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/08/31/the-unbearable-lightness-of-coloring-maps/</guid>
      <description>The Federal Bureau of Investigation (FBI) has lead responsibilities for protecting the United States against domestic crimes initiated abroad. These responsibilities include protection against “covert actions by foreign governments to influence U.S. political sentiment or public discourse” (https://www.fbi.gov/investigate/counterintelligence/foreign-influence). It has illustrated its mission description with a world map that appears to classify nations by the threats they pose.
The map has no description or legend, but uses several shades of blue to distinguish among countries.</description>
    </item>
    
    <item>
      <title>AI and the Oracle at Delphi</title>
      <link>/2018/08/30/ai-and-the-oracle-at-delphi/</link>
      <pubDate>Thu, 30 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/08/30/ai-and-the-oracle-at-delphi/</guid>
      <description>I attended a nice Meetup last night, and one of the speakers quoted Turing’s description of a program able to modify its own instructions as a good description of artificial intelligence (AI) and another had a nifty typology relating all the standard tools in data science to their role in AI. This set me to thinking about the standards to which AI should be held.
I began a thought experiment:</description>
    </item>
    
    <item>
      <title>How to debone linear regression output in Python</title>
      <link>/2018/08/29/how-to-debone-linear-regression-output-in-python/</link>
      <pubDate>Wed, 29 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/08/29/how-to-debone-linear-regression-output-in-python/</guid>
      <description>This post makes a trio with two most recent blogs on the same subject for R and Excel, this time in Python usking the sklearn package.
The example given in the official documentation (https://goo.gl/GGmUKK) is somewhat sketchy and uses a different dataset than the previous two examples. Although the example dataset is different, my main purpose is to illustrate the default output.
 OLS Regression Results ============================================================================== Dep. Variable: y R-squared: 0.</description>
    </item>
    
    <item>
      <title>How to debone the output of a linear regression model</title>
      <link>/2018/08/27/how-to-debone-the-output-of-a-linear-regression-model/</link>
      <pubDate>Mon, 27 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/08/27/how-to-debone-the-output-of-a-linear-regression-model/</guid>
      <description>I was recently puzzling over an academic paper in the social sciences with a multiple linear regression model that seemed off. (Communication with the authors educated me on considerations that resolved my concerns.)
During the course of my puzzling, I compared what I was seeing as model output in the paper and what I expected to see based on experience. The embarrassing revelation dawned that I didn’t actually know what all those components meant.</description>
    </item>
    
    <item>
      <title>The plural of data science is not formulae</title>
      <link>/2018/08/14/the-plural-of-data-science-is-not-formulae/</link>
      <pubDate>Tue, 14 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/08/14/the-plural-of-data-science-is-not-formulae/</guid>
      <description>The WSJ report of academic research on career hot streaks has snagged a lot of LinkedIn eyeballs today (Career ‘hot steaks’ are real 1h ago • 3,526 readers).
Reading the paper (https://goo.gl/2Mwqjn), you can see that it is an observational study of a convenience sample (these were the people about whom data were available, in the thousands or tens of thousands, an impressive collection).
Two mysteries: Why were the data not stratified into a training set and a test set?</description>
    </item>
    
    <item>
      <title>Analytic Data Scientists -- know when to fold &#39;em</title>
      <link>/2018/08/12/analytic-data-scientists-know-when-to-fold-em/</link>
      <pubDate>Sun, 12 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/08/12/analytic-data-scientists-know-when-to-fold-em/</guid>
      <description>In the days of our forebearers, if a tool broke, you were likely to fix it yourself. Long time passing, of course, the shadetree mechanic has been an endangered species. And no one would hire a carpenter who didn’t own his own tools.
I’ve been one to use my own tools. I have to admit to being, at times, cavalier about corporate policies strictly forbidding the use of employee owned computers, at least in the building.</description>
    </item>
    
    <item>
      <title>Nathan Yau on the challenges of thematic maps</title>
      <link>/2018/08/09/nathan-yau-on-the-challenges-of-thematic-maps/</link>
      <pubDate>Thu, 09 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/08/09/nathan-yau-on-the-challenges-of-thematic-maps/</guid>
      <description>If you are a paying member of Flowing Data (well worth the modest subscription), you will have received his email, reproduced at a paywalled portion of the site.
He gives a detailed critique of a precinct-by-precinct map of the 2016 presidential election, nationwide, showing the number of votes for Trump and Clinton and the nearest precinct in which the opposing candidate was in the majority.
He compares what the map purports to show with what it actually does show, which is the raw total of votes (ho-hum, we’ve known that for a long time) and the percentages.</description>
    </item>
    
    <item>
      <title>An error message is as much of a question as it is an answer</title>
      <link>/2018/08/05/an-error-message-is-as-much-of-a-question-as-it-is-an-answer/</link>
      <pubDate>Sun, 05 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/08/05/an-error-message-is-as-much-of-a-question-as-it-is-an-answer/</guid>
      <description>A question on datascience.stackexchange asked the reason for a Python syntax error
SyntaxError: can&amp;#39;t assign to literal Another poster had the correct change to fix the error but the explanation didn’t reflect what the OP needed to understand the problem behind the problem, which was failing to be namespace aware – he was trying to perform an operation on an undefined object.
When you find the answer to a question you don’t understand, you can expect to see it again.</description>
    </item>
    
    <item>
      <title>Newtonian Data Science</title>
      <link>/2018/08/04/newtonian-data-science/</link>
      <pubDate>Sat, 04 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/08/04/newtonian-data-science/</guid>
      <description>Most advanced machine learning and AI strike me as deterministic finite state machines with an error term. Properly tuned, the same input should produce much the same output every time. Like Newtonian physics, they can be complicated, but deconstructible into simple components. Like Newtonian physics, as well, they are highly accurate and reliable within their domain.
What happens when we start applying the same tools to complex systems? What are the complex systems of importance that refuse to yield identical results with identical inputs?</description>
    </item>
    
  </channel>
</rss>