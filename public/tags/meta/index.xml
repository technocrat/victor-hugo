<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Meta on Locus: Richard Careaga</title>
    <link>/tags/meta/</link>
    <description>Recent content in Meta on Locus: Richard Careaga</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 10 Sep 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/meta/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Cognitive styles of data science</title>
      <link>/2018/09/10/cognitive-styles-of-data-science/</link>
      <pubDate>Mon, 10 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/09/10/cognitive-styles-of-data-science/</guid>
      <description>Yihui Xie of RMarkdown fame has a long, thoughtful post (https://goo.gl/WjA7t8) on a debate for and against working in various types of interactive notebooks, such as Juypter for the Python platform, IDEs like RStudio in its so-called &amp;ldquo;notebook mode&amp;rdquo; and the old school heavy code commenting, among other approaches. Although that&amp;rsquo;s the primary subject, he weaves in some astute observations of the differences among &amp;ldquo;data scientists&amp;rdquo; based on whether their perspective grows from data origins or is aimed at ultimately producing software.</description>
    </item>
    
    <item>
      <title>AI and the Oracle at Delphi</title>
      <link>/2018/08/30/ai-and-the-oracle-at-delphi/</link>
      <pubDate>Thu, 30 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/08/30/ai-and-the-oracle-at-delphi/</guid>
      <description>I attended a nice Meetup last night, and one of the speakers quoted Turing&amp;rsquo;s description of a program able to modify its own instructions as a good description of artificial intelligence (AI) and another had a nifty typology relating all the standard tools in data science to their role in AI. This set me to thinking about the standards to which AI should be held.
I began a thought experiment:</description>
    </item>
    
    <item>
      <title>The plural of data science is not formulae</title>
      <link>/2018/08/14/the-plural-of-data-science-is-not-formulae/</link>
      <pubDate>Tue, 14 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/08/14/the-plural-of-data-science-is-not-formulae/</guid>
      <description>The WSJ report of academic research on career hot streaks has snagged a lot of LinkedIn eyeballs today (Career &amp;lsquo;hot steaks&amp;rsquo; are real 1h ago â€¢ 3,526 readers).
Reading the paper (https://goo.gl/2Mwqjn), you can see that it is an observational study of a convenience sample (these were the people about whom data were available, in the thousands or tens of thousands, an impressive collection).
Two mysteries: Why were the data not stratified into a training set and a test set?</description>
    </item>
    
    <item>
      <title>Newtonian Data Science</title>
      <link>/2018/08/04/newtonian-data-science/</link>
      <pubDate>Sat, 04 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/08/04/newtonian-data-science/</guid>
      <description>Most advanced machine learning and AI strike me as deterministic finite state machines with an error term. Properly tuned, the same input should produce much the same output every time. Like Newtonian physics, they can be complicated, but deconstructible into simple components. Like Newtonian physics, as well, they are highly accurate and reliable within their domain.
What happens when we start applying the same tools to complex systems? What are the complex systems of importance that refuse to yield identical results with identical inputs?</description>
    </item>
    
  </channel>
</rss>